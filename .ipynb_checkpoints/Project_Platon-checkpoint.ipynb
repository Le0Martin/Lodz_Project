{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establishing connection to MongoDB server running on specified IP address and port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient  # Import MongoClient class\n",
    "from datetime import datetime  # Import datetime \n",
    "\n",
    "# Defining get_db_connection function which receives ip, port and database name (db_name)\n",
    "def get_db_connection(ip, port, db_name):\n",
    "    try:\n",
    "        # Create an instance of the class MongoClient. \n",
    "        # This initiates a connection to the MongoDB server on the specified IP and port\n",
    "        client = MongoClient(ip, port)\n",
    "\n",
    "        # Once the connection is established, we can access the specific database with the name 'db_name'\n",
    "        db = client[db_name]\n",
    "\n",
    "        # The function returns the 'db' object that allows interaction with the database\n",
    "        return db\n",
    "\n",
    "    # This block will be executed if there is an exception during the 'try' execution\n",
    "    except Exception as e:\n",
    "        # Prints an error message with the exception description\n",
    "        print(f\"Error connecting to database: {e}\")\n",
    "\n",
    "        # Returns None if the connection failed\n",
    "        return None\n",
    "\n",
    "# establishing connection to the MongoDB server\n",
    "db = get_db_connection('localhost', 27017, 'myDatabase')\n",
    "\n",
    "# If the function returned None, then the connection failed\n",
    "if db is None:\n",
    "    print(\"Database connection failed!\")\n",
    "\n",
    "else:\n",
    "    print(\"Database connection successful!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This set of functions filters data in a MongoDB collection according to different criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Function to filter documents based on fields \"sequence.channel\" and \"sequence.service\"\n",
    "def filter_by_channel_and_service(db, collection_name, channel, service):\n",
    "    query = {\"sequence.channel\": channel, \"sequence.service\": service}\n",
    "    print(f\"Query: {query}\")\n",
    "    # Executes the query on the specified collection\n",
    "    result = db[collection_name].find(query)\n",
    "    return result\n",
    "\n",
    "# Function to get the timestamp documents \n",
    "def get_time_range(db, collection):\n",
    "    # Searches for the first document based on the \"sequence.timestamp\" field in ascending order\n",
    "    first_document = db[collection].find().sort(\"sequence.timestamp\", 1).limit(1)\n",
    "    # Searches for the last document based on the \"sequence.timestamp\" field in descending order\n",
    "    last_document = db[collection].find().sort(\"sequence.timestamp\", -1).limit(1)\n",
    "\n",
    "    # Extract timestamp from first and last document\n",
    "    start_time = first_document[0][\"sequence\"][\"timestamp\"]\n",
    "    end_time = last_document[0][\"sequence\"][\"timestamp\"]\n",
    "\n",
    "    return start_time, end_time\n",
    "\n",
    "# Function to filter documents based on a time range\n",
    "def filter_by_date(db, collection, start_time, end_time):\n",
    "    try:\n",
    "        # Build the search query\n",
    "        query = {\n",
    "            \"sequence.timestamp\": {\n",
    "                \"$gte\": start_time,\n",
    "                \"$lte\": end_time\n",
    "            }\n",
    "        }\n",
    "        count = db[collection].count_documents(query)\n",
    "        print(f\"Count: {count}\")\n",
    "        cursor = db[collection].find(query)\n",
    "        return cursor\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erro: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to filter documents \"sequence.schema\"\n",
    "def filter_by_schema(db, collection_name, schema):\n",
    "    query = {\"sequence.schema\": schema}\n",
    "    result = db[collection_name].find(query)\n",
    "    return result\n",
    "\n",
    "# Function to filter documents \"payload.timeout\"\n",
    "def filter_by_timeout(db, collection_name, timeout):\n",
    "    query = {\"payload.timeout\": timeout}\n",
    "    result = db[collection_name].find(query)\n",
    "    return result\n",
    "\n",
    "# Function to filter documents \"payload.publishes\"\n",
    "def filter_by_publishes(db, collection_name, publishes):\n",
    "    query = {\"payload.publishes\": publishes}\n",
    "    result = db[collection_name].find(query)\n",
    "    return result\n",
    "\n",
    "# Function to filter documents \"payload.subscribes\"\n",
    "def filter_by_subscribes(db, collection_name, subscribes):\n",
    "    query = {\"payload.subscribes\": subscribes}\n",
    "    result = db[collection_name].find(query)\n",
    "    return result\n",
    "\n",
    "# Function to filter documents \"payload.next_alive_interval\"\n",
    "def filter_by_next_alive_interval(db, collection_name, next_alive_interval):\n",
    "    # If next_alive_interval is None, returns all documents\n",
    "    if next_alive_interval is None:\n",
    "        return db[collection_name].find() \n",
    "    else:\n",
    "        query = {\"payload.next_alive_interval\": next_alive_interval}\n",
    "        result = db[collection_name].find(query)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code uses the get_time_range function to get the start time (start_time) and end time (end_time) of the documents in the \"myCollection\" collection of the MongoDB database.\n",
    "\n",
    "These times are based on the \"sequence.timestamp\" field of the documents in the collection. The get_time_range function searches for the oldest  and the newest document and returns their respective times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time, end_time = get_time_range(db, \"myCollection\")\n",
    "print(f\"Start time: {start_time}\")\n",
    "print(f\"End time: {end_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = \"2021-03-29T14:13:34.249+02:00\"\n",
    "end_time = \"2021-03-29T14:14:01.285+02:00\"\n",
    "cursor = filter_by_date(db, \"myCollection\", start_time, end_time)\n",
    "if cursor:\n",
    "    for document in cursor:\n",
    "        print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining test parameters\n",
    "collection_name = \"myCollection\"\n",
    "channel = \"status\"\n",
    "service = \"mediator\"\n",
    "\n",
    "cursor = filter_by_channel_and_service(db, collection_name, channel, service)\n",
    "\n",
    "# Checking if the function returned a cursor\n",
    "if cursor is not None:\n",
    "    for document in cursor:\n",
    "        print(document)\n",
    "else:\n",
    "    print(\"No documents found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining test parameters\n",
    "collection_name = \"myCollection\"\n",
    "schema = \"schema_status\"\n",
    "\n",
    "cursor = filter_by_schema(db, collection_name, schema)\n",
    "\n",
    "# Checking if the function returned a cursor\n",
    "if cursor is not None:\n",
    "    for document in cursor:\n",
    "        print(document)\n",
    "else:\n",
    "    print(\"No documents found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining test parameters\n",
    "collection_name = \"myCollection\"\n",
    "timeout = 20000\n",
    "\n",
    "cursor = filter_by_timeout(db, collection_name, timeout)\n",
    "\n",
    "# Checking if the function returned a cursor\n",
    "if cursor is not None:\n",
    "    for document in cursor:\n",
    "        print(document)\n",
    "else:\n",
    "    print(\"No documents found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining test parameters\n",
    "collection_name = \"myCollection\"\n",
    "publishes = []\n",
    "subscribes = [\"status\"]\n",
    "next_alive_interval = 3000\n",
    "\n",
    "cursor = filter_by_publishes(db, collection_name, publishes)\n",
    "\n",
    "# Checking if the function returned a cursor\n",
    "if cursor is not None:\n",
    "    for document in cursor:\n",
    "        print(document)\n",
    "else:\n",
    "    print(\"No documents found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = filter_by_subscribes(db, collection_name, subscribes)\n",
    "\n",
    "# Checking if the function returned a cursor\n",
    "if cursor is not None:\n",
    "    for document in cursor:\n",
    "        print(document)\n",
    "else:\n",
    "    print(\"No documents found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = filter_by_next_alive_interval(db, collection_name, next_alive_interval)\n",
    "\n",
    "# Checking if the function returned a cursor\n",
    "if cursor is not None:\n",
    "    for document in cursor:\n",
    "        print(document)\n",
    "else:\n",
    "    print(\"No documents found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_available_channels(db, collection_name):\n",
    "\n",
    "This function returns all distinct channels present in the documents of the specified collection. It uses MongoDB's aggregation operation to group the documents by the \"sequence.channel\" key and return each distinct channel value.\n",
    "\n",
    "\n",
    "get_available_services(db, collection_name):\n",
    "\n",
    "This function is similar to the get_available_channels function, but groups documents by service instead of channel.\n",
    "\n",
    "\n",
    "get_oldest_and_newest_date_by_channel(db, collection_name, channel):\n",
    "\n",
    "This function returns the earliest and latest dates for a specific channel.\n",
    "\n",
    "\n",
    "get_oldest_and_newest_date_by_schema(db, collection_name, schema):\n",
    "\n",
    "This function is similar to get_oldest_and_newest_date_by_channel, but filters documents by schema instead of channel.\n",
    "\n",
    "\n",
    "get_messages_by_service(db, collection_name, service):\n",
    "\n",
    "This function returns information about all channels for a specific service. It groups documents by channel, counts the number of records, and finds the oldest and newest dates for each channel.\n",
    "\n",
    "\n",
    "get_message_fields(db, collection_name, channel, service):\n",
    "\n",
    "This function returns information about the fields in the document payload for a specific channel and service. It returns the name of each field, plus a placeholder for the field type, size, and data, which you'll need to fill in based on the schema and documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_channels(db, collection_name):\n",
    "    # Groups documents by the key \"sequence.channel\" and returns the result\n",
    "    pipeline = [\n",
    "        {\"$group\": {\"_id\": \"$sequence.channel\"}}\n",
    "    ]\n",
    "    # Uses the aggregation operation to run the pipeline on the database\n",
    "    result = db[collection_name].aggregate(pipeline)\n",
    "    # Creates a list of all returned channels\n",
    "    channels = [doc[\"_id\"] for doc in result]\n",
    "    return channels\n",
    "\n",
    "\n",
    "def get_available_services(db, collection_name):\n",
    "    # Groups documents by the key \"sequence.service\" and returns the result\n",
    "    pipeline = [\n",
    "        {\"$group\": {\"_id\": \"$sequence.service\"}}\n",
    "    ]\n",
    "    # Uses the aggregation operation to run the pipeline on the database\n",
    "    result = db[collection_name].aggregate(pipeline)\n",
    "    # Creates a list of all returned services\n",
    "    services = [doc[\"_id\"] for doc in result]\n",
    "    return services\n",
    "\n",
    "def get_oldest_and_newest_date_by_channel(db, collection_name, channel):\n",
    "    # Filters documents by the specified channel and groups them to get the oldest and newest dates\n",
    "    pipeline = [\n",
    "        {\"$match\": {\"sequence.channel\": channel}},\n",
    "        {\"$group\": {\"_id\": None, \"oldest\": {\"$min\": \"$sequence.timestamp\"}, \"newest\": {\"$max\": \"$sequence.timestamp\"}}}\n",
    "    ]\n",
    "    # Uses the aggregation operation to run the pipeline on the database\n",
    "    result = db[collection_name].aggregate(pipeline)\n",
    "    # Get the first document returned\n",
    "    document = next(result, None)\n",
    "    if document:\n",
    "        oldest_date = document[\"oldest\"]\n",
    "        newest_date = document[\"newest\"]\n",
    "        return oldest_date, newest_date\n",
    "    else:\n",
    "        return None, None\n",
    "    \n",
    "def get_oldest_and_newest_date_by_schema(db, collection_name, schema):\n",
    "    # Filters the documents by the specified schema and groups them to get the oldest and newest dates\n",
    "    pipeline = [\n",
    "        {\"$match\": {\"sequence.schema\": schema}},\n",
    "        {\"$group\": {\"_id\": None, \"oldest\": {\"$min\": \"$sequence.timestamp\"}, \"newest\": {\"$max\": \"$sequence.timestamp\"}}}\n",
    "    ]\n",
    "    # Uses the aggregation operation to run the pipeline on the database\n",
    "    result = db[collection_name].aggregate(pipeline)\n",
    "    # Get the first document returned\n",
    "    document = next(result, None)\n",
    "    if document:\n",
    "        oldest_date = document[\"oldest\"]\n",
    "        newest_date = document[\"newest\"]\n",
    "        return oldest_date, newest_date\n",
    "    else:\n",
    "        return None, None\n",
    "    \n",
    "def get_messages_by_service(db, collection_name, service):\n",
    "    # Filters documents by specified service, groups them by channel, and returns information about each group\n",
    "    pipeline = [\n",
    "        {\"$match\": {\"sequence.service\": service}},\n",
    "        {\"$group\": {\"_id\": \"$sequence.channel\", \"schema\": {\"$first\": \"$sequence.schema\"}, \"records\": {\"$sum\": 1}, \"since\": {\"$min\": \"$sequence.timestamp\"}, \"until\": {\"$max\": \"$sequence.timestamp\"}}},\n",
    "        {\"$project\": {\"_id\": 0, \"channel\": \"$_id\", \"schema\": 1, \"records\": 1, \"since\": 1, \"until\": 1}}\n",
    "    ]\n",
    "    # Uses the aggregation operation to run the pipeline on the database\n",
    "    result = db[collection_name].aggregate(pipeline)\n",
    "    # Creates a list of all returned messages\n",
    "    messages = []\n",
    "    for doc in result:\n",
    "        message = {\n",
    "            \"channel\": doc[\"channel\"],\n",
    "            \"schema\": doc[\"schema\"],\n",
    "            \"records\": doc[\"records\"],\n",
    "            \"since\": doc[\"since\"],\n",
    "            \"until\": doc[\"until\"]\n",
    "        }\n",
    "        messages.append(message)\n",
    "    return messages\n",
    "\n",
    "def get_message_fields(db, collection_name, channel, service):\n",
    "    # Filters the documents by the specified channel and service, extracts the fields from the payload and returns information about each field\n",
    "    pipeline = [\n",
    "        {\"$match\": {\"sequence.channel\": channel, \"sequence.service\": service}},\n",
    "        {\"$limit\": 1},\n",
    "        {\"$project\": {\"fields\": {\"$objectToArray\": \"$payload\"}}},\n",
    "        {\"$unwind\": \"$fields\"},\n",
    "        {\"$group\": {\"_id\": None, \"fields\": {\"$push\": \"$fields.k\"}}},\n",
    "        {\"$project\": {\"_id\": 0, \"fields\": 1}}\n",
    "    ]\n",
    "    # Uses the aggregation operation to run the pipeline on the database\n",
    "    result = db[collection_name].aggregate(pipeline)\n",
    "    # Get the first document returned\n",
    "    document = next(result, None)\n",
    "    if document:\n",
    "        fields = document[\"fields\"]\n",
    "        num_fields = len(fields)\n",
    "        data = []\n",
    "        for i, field in enumerate(fields):\n",
    "            field_data = {\n",
    "                \"field\": field,\n",
    "                \"type_of_field\": \"\",  # needs to be filled in based on the schema\n",
    "                \"size\": 0,  # needs to be filled in based on the schema\n",
    "                \"data\": []  # needs to be filled in based on the documents\n",
    "            }\n",
    "            data.append({str(i): field_data})\n",
    "        return {\n",
    "            \"status\": \"OK\",\n",
    "            \"service\": service,\n",
    "            \"channel\": channel,\n",
    "            \"schema\": \"\",  # Schema needs to be filled\n",
    "            \"since\": \"\",  # The oldest date needs to be filled in based on the documents\n",
    "            \"to\": \"\",  # The newest date needs to be filled in based on the documents\n",
    "            \"fields\": num_fields,\n",
    "            \"size\": num_fields,\n",
    "            \"data\": data\n",
    "        }\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the function get_available_channels\n",
    "channels = get_available_channels(db, \"myCollection\")\n",
    "print(\"Available Channels:\")\n",
    "print(channels)\n",
    "\n",
    "# Testing the function get_available_services\n",
    "services = get_available_services(db, \"myCollection\")\n",
    "print(\"Available Services:\")\n",
    "print(services)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the function get_oldest_and_newest_date_by_channel\n",
    "channel = \"NI_vortex_measurement\"\n",
    "oldest_date, newest_date = get_oldest_and_newest_date_by_channel(db, \"myCollection\", channel)\n",
    "print(f\"Channel: {channel}\")\n",
    "print(f\"Oldest Date: {oldest_date}\")\n",
    "print(f\"Newest Date: {newest_date}\")\n",
    "\n",
    "# Testing the function get_oldest_and_newest_date_by_schema\n",
    "schema = \"NI_vortex_measurement\"\n",
    "oldest_date, newest_date = get_oldest_and_newest_date_by_schema(db, \"myCollection\", schema)\n",
    "print(f\"Schema: {schema}\")\n",
    "print(f\"Oldest Date: {oldest_date}\")\n",
    "print(f\"Newest Date: {newest_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the function get_messages_by_service\n",
    "service = \"NI_CYKLON\"\n",
    "messages = get_messages_by_service(db, \"myCollection\", service)\n",
    "print(f\"Messages sent by service '{service}':\")\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the function get_message_fields\n",
    "channel = \"NI_vortex_control\"\n",
    "service = \"TomoKISStudio#15995\"\n",
    "fields_info = get_message_fields(db, \"myCollection\", channel, service)\n",
    "print(\"Message Fields:\")\n",
    "print(fields_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class is used to represent a user's configuration, including an IP address, a port, some filters, and the location of a logger. Configuration information can be saved to a JSON file and loaded from a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Define the class UserConfig\n",
    "class UserConfig:\n",
    "    def __init__(self, ip_address, port, filters, logger_location):\n",
    "        self.ip_address = ip_address\n",
    "        self.port = port\n",
    "        self.filters = filters\n",
    "        self.logger_location = logger_location\n",
    "\n",
    "    # Method to save user configuration to a JSON file\n",
    "    def save(self, filename):\n",
    "        with open(filename, 'w') as f:  # Open file in recording mode\n",
    "            # Use json module's dump method to write configuration to file\n",
    "            # self.__dict__ is a dictionary that contains the properties of the class instance\n",
    "            json.dump(self.__dict__, f)  \n",
    "\n",
    "    # Class method for loading user configuration from a JSON file\n",
    "    @classmethod\n",
    "    def load(cls, filename):\n",
    "        with open(filename, 'r') as f:  # Open file in read mode\n",
    "            config = json.load(f)  # Load the content of the JSON file into a dictionary\n",
    "        return cls(**config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new configuration\n",
    "config = UserConfig('127.0.0.1', 8000, {\"channel\": \"ET_Tomograms\", \"service\": \"TomoKISStudio#2853\"}, 'app.log')\n",
    "\n",
    "# Save the configuration to a file\n",
    "config.save('user_config.json')\n",
    "\n",
    "# Load configuration from a file\n",
    "loaded_config = UserConfig.load('user_config.json')\n",
    "print(loaded_config.ip_address)  # Outputs: 127.0.0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python script that creates a GUI (Grafical User Interface) for filtering and visualizing data from a MongoDB collection. Here are the details of the script's main components:\n",
    "\n",
    "Auxiliary functions: Functions that assist in reading and writing the JSON configuration file, connecting to the MongoDB database, initializing the log and manipulating data.\n",
    "\n",
    "GUI-specific functions: Functions that perform specific actions when buttons are pressed in the GUI. This includes filtering data based on input values, obtaining channels, services, oldest and newest dates, messages by service, message fields, and plotting graphs.\n",
    "\n",
    "create_gui() function: The main function that creates the GUI using the tkinter package. It creates labels, input fields, buttons, and a text area to display the results.\n",
    "\n",
    "Connection to MongoDB database: The script connects to MongoDB using the IP address and port provided in the JSON configuration file.\n",
    "\n",
    "Exception Handling: The script also has exception handling to deal with  possible errors during execution.\n",
    "\n",
    "Settings: The script reads a configuration file at the beginning to determine the database connection parameters, filters to apply, and the log file. If the configuration file does not exist, it will create one with default values.\n",
    "\n",
    "Graph Plotting: Using the matplotlib library, this script is capable of plotting graphs with the filtered data from MongoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from pymongo import MongoClient\n",
    "import logging\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from matplotlib.figure import Figure\n",
    "from tkinter import messagebox, Scrollbar, Canvas\n",
    "\n",
    "# Function to retrieve MongoDB payload data\n",
    "def get_payload_data(cursor):\n",
    "    data = []\n",
    "    for document in cursor:\n",
    "        if \"payload\" in document:\n",
    "            payload = document[\"payload\"]\n",
    "            if \"image\" in payload:\n",
    "                image = payload[\"image\"]\n",
    "                if \"data\" in image:\n",
    "                    item = {\n",
    "                        \"timestamp\": document[\"sequence\"][\"timestamp\"],\n",
    "                        \"data\": image[\"data\"][0]\n",
    "                    }\n",
    "                    data.append(item)\n",
    "    return data\n",
    "\n",
    "# Function to start logging\n",
    "def init_logging(log_file):\n",
    "    logging.basicConfig(filename=log_file, level=logging.ERROR,\n",
    "                        format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    \n",
    "# Function to load the configuration file\n",
    "def load_config(config_file):\n",
    "    with open(config_file, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    return config\n",
    "\n",
    "# Function to save the configuration file\n",
    "def save_config(config, config_file):\n",
    "    with open(config_file, 'w') as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "\n",
    "# Main function to create the GUI\n",
    "def create_gui(db, collection_name):\n",
    "\n",
    "    # Auxiliary functions\n",
    "    def execute_filters():\n",
    "        try:\n",
    "            channel = channel_entry.get()\n",
    "            service = service_entry.get()\n",
    "            schema = schema_entry.get()\n",
    "            publishes = publishes_entry.get().split(\",\") if publishes_entry.get() else []\n",
    "            subscribes = subscribes_entry.get().split(\",\") if subscribes_entry.get() else []\n",
    "            next_alive_interval = int(next_alive_interval_entry.get()) if next_alive_interval_entry.get() else None\n",
    "\n",
    "            # create filter\n",
    "            filters = {}\n",
    "            if channel:\n",
    "                filters[\"sequence.channel\"] = channel\n",
    "            if service:\n",
    "                filters[\"sequence.service\"] = service\n",
    "            if schema:\n",
    "                filters[\"sequence.schema\"] = schema\n",
    "            if publishes:\n",
    "                filters[\"payload.publishes\"] = {\"$in\": publishes}\n",
    "            if subscribes:\n",
    "                filters[\"payload.subscribes\"] = {\"$in\": subscribes}\n",
    "            if next_alive_interval is not None:\n",
    "                filters[\"payload.next_alive_interval\"] = next_alive_interval\n",
    "            \n",
    "            cursor = db[collection_name].find(filters)\n",
    "\n",
    "            # Output the results\n",
    "            results_text.delete('1.0', tk.END)\n",
    "            results_text.insert(tk.END, \"Filtered Data:\\n\")\n",
    "            for document in cursor:\n",
    "                results_text.insert(tk.END, str(document) + \"\\n\")\n",
    "            results_text.insert(tk.END, \"End of results.\")\n",
    "        \n",
    "            # Save user's filter values\n",
    "            config['filters'] = {\n",
    "                'channel': channel,\n",
    "                'service': service,\n",
    "                'schema': schema,\n",
    "                'publishes': publishes,\n",
    "                'subscribes': subscribes,\n",
    "                'next_alive_interval': next_alive_interval\n",
    "            }\n",
    "            save_config(config, config_file)\n",
    "\n",
    "        except Exception as e:\n",
    "            error_message = str(e)\n",
    "            messagebox.showerror(\"Error\", error_message)\n",
    "            logging.error(f\"Error executing filters: {error_message}\")\n",
    "                \n",
    "    def execute_get_channels():\n",
    "        try:\n",
    "            results_text.delete('1.0', tk.END)  # New line to clear the text field\n",
    "            channels = get_available_channels(db, collection_name)\n",
    "            results_text.insert(tk.END, f\"Channels: {channels}\\n\")\n",
    "        except Exception as e:\n",
    "            error_message = str(e)\n",
    "            messagebox.showerror(\"Error\", str(e))\n",
    "            logging.error(f\"Error getting channels: {error_message}\")\n",
    "\n",
    "    def execute_get_services():\n",
    "        try:\n",
    "            results_text.delete('1.0', tk.END)  # New line to clear the text field\n",
    "            services = get_available_services(db, collection_name)\n",
    "            results_text.insert(tk.END, f\"Services: {services}\\n\")\n",
    "        except Exception as e:\n",
    "            error_message = str(e)\n",
    "            messagebox.showerror(\"Error\", str(e))\n",
    "            logging.error(f\"Error getting services: {error_message}\")\n",
    "\n",
    "    def execute_get_oldest_and_newest_date_by_channel():\n",
    "        try:\n",
    "            results_text.delete('1.0', tk.END)  # New line to clear the text field\n",
    "            channel = channel_entry.get()\n",
    "            oldest_date, newest_date = get_oldest_and_newest_date_by_channel(db, collection_name, channel)\n",
    "            results_text.insert(tk.END, f\"For channel '{channel}', oldest date: {oldest_date}, newest date: {newest_date}\\n\")\n",
    "        except Exception as e:\n",
    "            error_message = str(e)\n",
    "            messagebox.showerror(\"Error\", str(e))\n",
    "            logging.error(f\"Error getting oldest and newest date by channel: {error_message}\")\n",
    "\n",
    "    def execute_get_oldest_and_newest_date_by_schema():\n",
    "        try:\n",
    "            results_text.delete('1.0', tk.END)  # New line to clear the text field\n",
    "            schema = schema_entry.get()\n",
    "            oldest_date, newest_date = get_oldest_and_newest_date_by_schema(db, collection_name, schema)\n",
    "            results_text.insert(tk.END, f\"For schema '{schema}', oldest date: {oldest_date}, newest date: {newest_date}\\n\")\n",
    "        except Exception as e:\n",
    "            error_message = str(e)\n",
    "            messagebox.showerror(\"Error\", str(e))\n",
    "            logging.error(f\"Error getting oldest and newest date by schema: {error_message}\")\n",
    "\n",
    "    def execute_get_messages_by_service():\n",
    "        try:\n",
    "            results_text.delete('1.0', tk.END)  # New line to clear the text field\n",
    "            service = service_entry.get()\n",
    "            messages = get_messages_by_service(db, collection_name, service)\n",
    "            results_text.insert(tk.END, f\"Messages by service '{service}': {messages}\\n\")\n",
    "        except Exception as e:\n",
    "            error_message = str(e)\n",
    "            messagebox.showerror(\"Error\", str(e))\n",
    "            logging.error(f\"Error getting messages by service: {error_message}\")\n",
    "\n",
    "    def execute_get_message_fields():\n",
    "        try:\n",
    "            results_text.delete('1.0', tk.END)  # New line to clear the text field\n",
    "            channel = channel_entry.get()\n",
    "            service = service_entry.get()\n",
    "            message_fields = get_message_fields(db, collection_name, channel, service)\n",
    "            results_text.insert(tk.END, f\"Message fields for channel '{channel}' and service '{service}': {message_fields}\\n\")\n",
    "        except Exception as e:\n",
    "            error_message = str(e)\n",
    "            messagebox.showerror(\"Error\", str(e))\n",
    "            logging.error(f\"Error getting messages by fields: {error_message}\")\n",
    "    \n",
    "    def plot_graph():\n",
    "        try:\n",
    "            # Gets values from input widgets\n",
    "            channel = channel_entry.get()\n",
    "            service = service_entry.get()\n",
    "            time0 = start_time\n",
    "            time1 = end_time\n",
    "\n",
    "            cursor = filter_by_channel_and_service(db, 'myCollection', channel, service)\n",
    "\n",
    "            data = get_payload_data(cursor)\n",
    "\n",
    "            df = pd.DataFrame(data)\n",
    "            df['data_0'] = df['data'].apply(lambda x: x[0] if len(x) > 0 else None)\n",
    "            df['data_1'] = df['data'].apply(lambda x: x[1] if len(x) > 1 else None)\n",
    "\n",
    "            df = df.dropna(subset=['data_0', 'data_1'])\n",
    "\n",
    "            fig = Figure(figsize=(10, 5))\n",
    "            a = fig.add_subplot(111)\n",
    "\n",
    "            a.plot(df['timestamp'], df['data_0'], label='first position of data row by time')\n",
    "            a.plot(df['timestamp'], df['data_1'], label='second position of data row by time')\n",
    "\n",
    "            a.set_title('Data over time')\n",
    "            a.set_ylabel('Value')\n",
    "            a.set_xlabel('Timestamp')\n",
    "            a.legend(loc='best')\n",
    "            a.text(0,0.07,\"start: \" + time0)\n",
    "            a.text(0,0.06,\"end: \" + time1)\n",
    "\n",
    "            # Create a new Frame for matplotlib figure\n",
    "            plot_frame = tk.Frame(frame)\n",
    "            plot_frame.grid(row=14, column=0, columnspan=2)\n",
    "\n",
    "            # Create tkinter widget for matplotlib plot\n",
    "            canvas = FigureCanvasTkAgg(fig, master=plot_frame) \n",
    "            canvas.draw()\n",
    "            canvas.get_tk_widget().pack()\n",
    "\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", str(e))\n",
    "\n",
    "     # GUI creation\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Data Filtering Tool\")\n",
    "    \n",
    "    # Creates the main Frame that will host the Canvas and the Scrollbar\n",
    "    main_frame = tk.Frame(root)\n",
    "    main_frame.pack(fill=tk.BOTH, expand=1)\n",
    "    \n",
    "    # Creates the Canvas\n",
    "    canvas = tk.Canvas(main_frame)\n",
    "    canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=1)\n",
    "    \n",
    "    # Creates the Scrollbar\n",
    "    scrollbar = tk.Scrollbar(main_frame, orient=tk.VERTICAL, command=canvas.yview)\n",
    "    scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "    \n",
    "    # Add the frame inside the canvas\n",
    "    frame = tk.Frame(canvas)\n",
    "    \n",
    "    # Add scrollbar to canvas\n",
    "    canvas.configure(yscrollcommand=scrollbar.set)\n",
    "    \n",
    "    # Add the frame to the canvas window\n",
    "    canvas.create_window((0,0), window=frame, anchor='nw')\n",
    "    \n",
    "    # Update canvas scrolling region when frame size changes\n",
    "    frame.bind('<Configure>', lambda e: canvas.configure(scrollregion=canvas.bbox('all')))\n",
    "\n",
    "    tk.Label(frame, text=\"Channel:\").grid(row=0, column=0)\n",
    "    channel_entry = tk.Entry(frame)\n",
    "    channel_entry.grid(row=0, column=1)\n",
    "\n",
    "    tk.Label(frame, text=\"Service:\").grid(row=1, column=0)\n",
    "    service_entry = tk.Entry(frame)\n",
    "    service_entry.grid(row=1, column=1)\n",
    "\n",
    "    tk.Label(frame, text=\"Schema:\").grid(row=2, column=0)\n",
    "    schema_entry = tk.Entry(frame)\n",
    "    schema_entry.grid(row=2, column=1)\n",
    "\n",
    "    tk.Label(frame, text=\"Publishes (comma-separated):\").grid(row=3, column=0)\n",
    "    publishes_entry = tk.Entry(frame)\n",
    "    publishes_entry.grid(row=3, column=1)\n",
    "\n",
    "    tk.Label(frame, text=\"Subscribes (comma-separated):\").grid(row=4, column=0)\n",
    "    subscribes_entry = tk.Entry(frame)\n",
    "    subscribes_entry.grid(row=4, column=1)\n",
    "\n",
    "    tk.Label(frame, text=\"Next alive interval:\").grid(row=5, column=0)\n",
    "    next_alive_interval_entry = tk.Entry(frame)\n",
    "    next_alive_interval_entry.grid(row=5, column=1)\n",
    "\n",
    "    filter_button = tk.Button(frame, text=\"Filter\", command=execute_filters)\n",
    "    filter_button.grid(row=6, column=0, columnspan=2)\n",
    "\n",
    "    plot_button = tk.Button(frame, text=\"Plot Graph\", command=plot_graph)\n",
    "    plot_button.grid(row=15, column=0, columnspan=2)\n",
    "\n",
    "    results_text = tk.Text(frame)\n",
    "    results_text.grid(row=7, column=0, columnspan=2)\n",
    "\n",
    "    # Additional buttons for functions\n",
    "    get_channels_button = tk.Button(frame, text=\"Get Channels\", command=execute_get_channels)\n",
    "    get_channels_button.grid(row=8, column=0, columnspan=2)\n",
    "        \n",
    "    get_services_button = tk.Button(frame, text=\"Get Services\", command=execute_get_services)\n",
    "    get_services_button.grid(row=9, column=0, columnspan=2)\n",
    "\n",
    "    get_oldest_and_newest_date_by_channel_button = tk.Button(frame, text=\"Get Oldest and Newest Date by Channel\", command=execute_get_oldest_and_newest_date_by_channel)\n",
    "    get_oldest_and_newest_date_by_channel_button.grid(row=10, column=0, columnspan=2)\n",
    "        \n",
    "    get_oldest_and_newest_date_by_schema_button = tk.Button(frame, text=\"Get Oldest and Newest Date by Schema\", command=execute_get_oldest_and_newest_date_by_schema)\n",
    "    get_oldest_and_newest_date_by_schema_button.grid(row=11, column=0, columnspan=2)\n",
    "\n",
    "    get_messages_by_service_button = tk.Button(frame, text=\"Get Messages by Service\", command=execute_get_messages_by_service)\n",
    "    get_messages_by_service_button.grid(row=12, column=0, columnspan=2)\n",
    "\n",
    "    get_message_fields_button = tk.Button(frame, text=\"Get Message Fields\", command=execute_get_message_fields)\n",
    "    get_message_fields_button.grid(row=13, column=0, columnspan=2)\n",
    "\n",
    "    frame.update_idletasks()\n",
    "\n",
    "# Configure the canvas scroll area to match the frame size\n",
    "    canvas.configure(scrollregion=canvas.bbox('all'))\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "config_file = 'config.json'\n",
    "\n",
    "# Load user config\n",
    "try:\n",
    "    config = load_config(config_file)\n",
    "except FileNotFoundError:\n",
    "    config = {\n",
    "        'db_ip': 'localhost',\n",
    "        'db_port': 27017,\n",
    "        'filters': {},\n",
    "        'log_file': 'app.log'\n",
    "    }\n",
    "\n",
    "init_logging(config['log_file'])\n",
    "init_logging('app.log')\n",
    "\n",
    "# Connecting to MongoDB Database\n",
    "db = get_db_connection('localhost', 27017, 'myDatabase')\n",
    "\n",
    "# Calling the function to create the UI\n",
    "create_gui(db, \"myCollection\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
